{
  "package_id": "package",
  "source": "imaging_exposure.pdf",
  "level": "introductory",
  "mcqs": [
    {
      "id": "pkg_exposure_01_mcq_d8dfa4",
      "question": "What is the basic idea of the Iterative Closest Point (ICP) algorithm?",
      "options": {
        "A": "To project 3D points onto 2D planes and iteratively adjust their alignment in 2D",
        "B": "To align 3D point clouds by iteratively reducing their nearest point pair distances",
        "C": "To use the iterative least squares method to estimate normals of adjacent points",
        "D": "To divide the point clouds into segments and align closest segments iteratively",
        "E": "To create meshes from point clouds and iteratively maximizing their overlap area"
      },
      "correct_option": "B",
      "difficulty": "easy",
      "learning_objective": "",
      "slide_refs": []
    },
    {
      "id": "pkg_exposure_01_mcq_53df15",
      "question": "What is the basic principle of structured light?",
      "options": {
        "A": "A laser scans the scene and measures the time-of-flight to obtain depth",
        "B": "The camera captures images under multiple light sources",
        "C": "Shading of a uniformly illuminated object is analyzed by a camera",
        "D": "Interference patterns reflected from the object are analyzed by a camera",
        "E": "A light pattern is projected onto the scene and observed by a camera"
      },
      "correct_option": "E",
      "difficulty": "easy",
      "learning_objective": "",
      "slide_refs": []
    },
    {
      "id": "pkg_exposure_01_mcq_d24427",
      "question": "How many 3D point correspondences in minimum are needed to solve the parameters of a general 3D affine transformation?",
      "options": {
        "A": "3",
        "B": "4",
        "C": "5",
        "D": "6",
        "E": "2"
      },
      "correct_option": "B",
      "difficulty": "easy",
      "learning_objective": "",
      "slide_refs": []
    },
    {
      "id": "pkg_exposure_01_mcq_39ad31",
      "question": "How does camera calibration differ from pose estimation?",
      "options": {
        "A": "Calibration requires point correspondences, pose estimation does not require correspondences",
        "B": "Calibration requires a checkerboard pattern, pose estimation uses a natural scene",
        "C": "Calibration determines both internal and external parameters, pose estimation only external parameters",
        "D": "Calibration estimates only internal parameters, pose estimation only external parameters",
        "E": "Calibration estimates external parameters, pose estimation estimates both internal and external parameters"
      },
      "correct_option": "B",
      "difficulty": "easy",
      "learning_objective": "",
      "slide_refs": []
    },
    {
      "id": "pkg_exposure_01_mcq_2c070b",
      "question": "What parameters are needed to represent a rigid 3D transformation?",
      "options": {
        "A": "Rotation and translation",
        "B": "Reflection and translation",
        "C": "Shear, rotation, and scale",
        "D": "Translation, scale, and reflection",
        "E": "Rotation, translation and scale"
      },
      "correct_option": "A",
      "difficulty": "easy",
      "learning_objective": "",
      "slide_refs": []
    },
    {
      "id": "pkg_exposure_01_mcq_c7ed86",
      "question": "What is the purpose of a projection matrix?",
      "options": {
        "A": "Perform a 3D affine transformation",
        "B": "Convert 3D to 2D coordinates",
        "C": "Convert 2D to 3D coordinates",
        "D": "Represent the internal camera parameters",
        "E": "Perform a 3D rigid transformation"
      },
      "correct_option": "B",
      "difficulty": "easy",
      "learning_objective": "",
      "slide_refs": []
    },
    {
      "id": "pkg_exposure_01_mcq_b4e2d2",
      "question": "In what cases does orthographic projection approximate perspective projection well?",
      "options": {
        "A": "When the focal length is small",
        "B": "When the object is far from the camera",
        "C": "When the camera is very close to the object",
        "D": "When the object is very large compared to its distance",
        "E": "When the camera's field of view is wide"
      },
      "correct_option": "B",
      "difficulty": "easy",
      "learning_objective": "",
      "slide_refs": []
    },
    {
      "id": "pkg_exposure_01_mcq_773b44",
      "question": "How does relative pose differ from absolute pose?",
      "options": {
        "A": "Relative pose involves only the rigid transformation while absolute pose involves also the internal camera parameters",
        "B": "Relative pose involves the rigid transformation and the internal camera parameters while absolute pose involves only the rigid transformation",
        "C": "Relative pose involves only rotational parameters while absolute pose involves also translational parameters",
        "D": "Relative pose is between two cameras while absolute pose is between a 3D object and a camera",
        "E": "Relative pose is between a 3D object and a camera while absolute pose is between two cameras"
      },
      "correct_option": "D",
      "difficulty": "easy",
      "learning_objective": "",
      "slide_refs": []
    },
    {
      "id": "pkg_exposure_01_mcq_d580a9",
      "question": "What is the difference between structure from motion (SfM) and multi-view stereo?",
      "options": {
        "A": "SfM requires known camera poses; multi-view stereo does not",
        "B": "SfM works with uncalibrated cameras; multi-view stereo requires calibrated cameras",
        "C": "SfM does not require known camera poses; multi-view stereo does",
        "D": "SfM is limited to two views; multi-view stereo uses multiple views",
        "E": "SfM can reconstruct scale; multi-view stereo cannot"
      },
      "correct_option": "B",
      "difficulty": "easy",
      "learning_objective": "",
      "slide_refs": []
    },
    {
      "id": "pkg_exposure_01_mcq_d7e7ee",
      "question": "What is the difference between the essential matrix and the fundamental matrix?",
      "options": {
        "A": "Essential matrix can handle uncalibrated cameras while fundamental matrix requires calibrated cameras",
        "B": "Essential matrix is for relative pose estimation while fundamental matrix is for absolute pose estimation",
        "C": "Essential matrix uses normalized image coordinates while fundamental matrix does not require normalization",
        "D": "Essential matrix is defined for arbitrary 3D objects while fundamental matrix is defined for objects on the epipolar plane",
        "E": "Essential matrix is for absolute pose estimation while fundamental matrix is for relative pose estimation"
      },
      "correct_option": "D",
      "difficulty": "easy",
      "learning_objective": "",
      "slide_refs": []
    }
  ]
}